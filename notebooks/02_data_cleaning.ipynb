{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-18T00:26:20.582174Z",
     "start_time": "2025-09-18T00:26:20.569585Z"
    }
   },
   "source": [
    "# StackOverlow Developer Survey - Data Cleaning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T00:26:23.675848Z",
     "start_time": "2025-09-18T00:26:22.256643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Load the dataset\n",
    "print(\"1. Loading the dataset...\")\n",
    "df = pd.read_csv('../data/raw/survey_results_public.csv')\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(f\"Initial shape: {df.shape}\")"
   ],
   "id": "d3d6e8c649ab0e77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading the dataset...\n",
      "Dataset loaded successfully.\n",
      "Initial shape: (49123, 170)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T00:26:24.788174Z",
     "start_time": "2025-09-18T00:26:24.782871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Basic Information\n",
    "print(\"\\n2. Basic information...\")\n",
    "print(f\"Dataset size: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ],
   "id": "a90a40c713dfce1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Basic information...\n",
      "Dataset size: 49123 rows, 170 columns\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T00:26:26.550494Z",
     "start_time": "2025-09-18T00:26:26.538908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Define target variable - We're predicting salary\n",
    "print(\"\\n3. Identifying target variable...\")\n",
    "target_column = 'ConvertedCompYearly'\n",
    "if target_column in df.columns:\n",
    "    print(f\"Target variable: {target_column}\")\n",
    "    print(f\"Target variable stats:\\n{df[target_column].describe()}\")\n",
    "    \n",
    "    # Check for missing values in target\n",
    "    target_missing = df[target_column].isna().sum()\n",
    "    print(f\"Missing values in target: {target_missing} ({target_missing/len(df)*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"target variable '{target_column}' not found in dataset.\")"
   ],
   "id": "f311b896c4c98139",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Identifying target variable...\n",
      "Target variable: ConvertedCompYearly\n",
      "Target variable stats:\n",
      "count    2.392800e+04\n",
      "mean     1.017916e+05\n",
      "std      4.619345e+05\n",
      "min      1.000000e+00\n",
      "25%      3.817100e+04\n",
      "50%      7.538350e+04\n",
      "75%      1.206302e+05\n",
      "max      5.000000e+07\n",
      "Name: ConvertedCompYearly, dtype: float64\n",
      "Missing values in target: 25195 (51.29%)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T00:26:27.869942Z",
     "start_time": "2025-09-18T00:26:27.763182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Analyze missing values....\")\n",
    "print(\"\\n4. Analyzing missing values...\")\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percentage = (missing_counts / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_counts.index,\n",
    "    'Missing_Count': missing_counts.values,\n",
    "    'Missing_Percentage': missing_percentage.values\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"Top 10 columns with most missing data:\")\n",
    "print(missing_df.head(10))"
   ],
   "id": "eccbef2b9f5f657",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Analyzing missing values...\n",
      "Top 10 columns with most missing data:\n",
      "                   Column  Missing_Count  Missing_Percentage\n",
      "163       AIAgentObsWrite          48859           99.462574\n",
      "96       SOTagsWant Entry          48693           99.124646\n",
      "95        SOTagsHaveEntry          48666           99.069682\n",
      "114     AIModelsWantEntry          48649           99.035075\n",
      "161      AIAgentOrchWrite          48646           99.028968\n",
      "54   JobSatPoints_15_TEXT          48459           98.648291\n",
      "159      AIAgentKnowWrite          48358           98.442685\n",
      "113     AIModelsHaveEntry          48348           98.422328\n",
      "130    SO_Actions_15_TEXT          48300           98.324614\n",
      "165       AIAgentExtWrite          48265           98.253364\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T00:26:29.479317Z",
     "start_time": "2025-09-18T00:26:29.431328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Drop columns with excessive missing data\n",
    "print(\"\\n5. Dropping columns with excessive missing data...\")\n",
    "# Drop columns with more than 50% missing values\n",
    "high_missing_cols = missing_df[missing_df['Missing_Percentage'] > 50]['Column'].tolist()\n",
    "print(f\"Dropping {len(high_missing_cols)} columns with > 50% missing data:\")\n",
    "for col in high_missing_cols:\n",
    "    print(f\" - {col} ({missing_df[missing_df['Column']==col]['Missing_Percentage'].values[0]:.1f}%)\")\n",
    "    # Print in alphabetical order\n",
    "# if len(high_missing_cols) > 10:\n",
    "#     print(f\" ... and {len(high_missing_cols) - 10} more.\")\n",
    "    \n",
    "df_cleaned = df.drop(columns=high_missing_cols)\n",
    "print(f\"Dataset shape after dropping high-missing columns: {df_cleaned.shape}\")\n",
    "# Print the difference in column size"
   ],
   "id": "2e70fee5fee6c40a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Dropping columns with excessive missing data...\n",
      "Dropping 71 columns with > 50% missing data:\n",
      " - AIAgentObsWrite (99.5%)\n",
      " - SOTagsWant Entry (99.1%)\n",
      " - SOTagsHaveEntry (99.1%)\n",
      " - AIModelsWantEntry (99.0%)\n",
      " - AIAgentOrchWrite (99.0%)\n",
      " - JobSatPoints_15_TEXT (98.6%)\n",
      " - AIAgentKnowWrite (98.4%)\n",
      " - AIModelsHaveEntry (98.4%)\n",
      " - SO_Actions_15_TEXT (98.3%)\n",
      " - AIAgentExtWrite (98.3%)\n",
      " - CommPlatformWantEntr (97.6%)\n",
      " - CommPlatformHaveEntr (97.0%)\n",
      " - DatabaseWantEntry (96.9%)\n",
      " - OfficeStackWantEntry (96.7%)\n",
      " - TechOppose_15_TEXT (96.7%)\n",
      " - TechEndorse_13_TEXT (95.9%)\n",
      " - DevEnvWantEntry (95.7%)\n",
      " - DatabaseHaveEntry (95.6%)\n",
      " - OfficeStackHaveEntry (94.7%)\n",
      " - WebframeWantEntry (94.7%)\n",
      " - AIAgentObserveSecure (94.5%)\n",
      " - DevEnvHaveEntry (94.4%)\n",
      " - PlatformWantEntry (93.7%)\n",
      " - LanguagesWantEntry (93.6%)\n",
      " - WebframeHaveEntry (93.3%)\n",
      " - AIAgentKnowledge (93.1%)\n",
      " - AIAgentOrchestration (92.3%)\n",
      " - AIAgentImpactStrongly disagree (92.3%)\n",
      " - PlatformHaveEntry (92.0%)\n",
      " - LanguagesHaveEntry (91.9%)\n",
      " - AIAgentImpactSomewhat disagree (88.2%)\n",
      " - AgentUsesGeneral (88.2%)\n",
      " - AIAgentImpactStrongly agree (86.4%)\n",
      " - AIAgentExternal (83.1%)\n",
      " - AIAgentChallengesStrongly disagree (81.1%)\n",
      " - AIAgentImpactNeutral (80.3%)\n",
      " - AIAgentImpactSomewhat agree (79.4%)\n",
      " - AIToolCurrently mostly AI (77.2%)\n",
      " - AIModelsAdmired (77.1%)\n",
      " - AIModelsWantToWorkWith (75.9%)\n",
      " - AIAgentChallengesSomewhat disagree (75.3%)\n",
      " - SOTagsAdmired (75.1%)\n",
      " - AIAgent_Uses (74.9%)\n",
      " - AIToolPlan to mostly use AI (73.9%)\n",
      " - SOTagsWantToWorkWith (72.4%)\n",
      " - WebframeAdmired (68.0%)\n",
      " - AIModelsHaveWorkedWith (66.9%)\n",
      " - DatabaseAdmired (64.8%)\n",
      " - WebframeWantToWorkWith (64.1%)\n",
      " - PlatformAdmired (63.8%)\n",
      " - SOTagsHaveWorkedWith (63.5%)\n",
      " - PlatformWantToWorkWith (60.5%)\n",
      " - DevEnvsAdmired (60.4%)\n",
      " - DatabaseWantToWorkWith (59.9%)\n",
      " - DevEnvsWantToWorkWith (58.1%)\n",
      " - AIToolCurrently partially AI (57.2%)\n",
      " - AIAgentChallengesNeutral (56.7%)\n",
      " - AIAgentChallengesSomewhat agree (55.4%)\n",
      " - OfficeStackAsyncAdmired (54.8%)\n",
      " - AIOpen (54.2%)\n",
      " - AIToolPlan to partially use AI (54.1%)\n",
      " - SO_Dev_Content (53.5%)\n",
      " - CommPlatformAdmired (53.5%)\n",
      " - WebframeHaveWorkedWith (53.2%)\n",
      " - AIAgentChallengesStrongly agree (53.0%)\n",
      " - OfficeStackAsyncWantToWorkWith (52.8%)\n",
      " - CommPlatformWantToWorkWith (52.5%)\n",
      " - LanguageAdmired (52.3%)\n",
      " - ConvertedCompYearly (51.3%)\n",
      " - PlatformHaveWorkedWith (50.7%)\n",
      " - SO_Actions_16 (50.5%)\n",
      "Dataset shape after dropping high-missing columns: (49123, 99)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T00:26:31.615444Z",
     "start_time": "2025-09-18T00:26:31.568849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6. Drop columns irrelevant to salary prediction\n",
    "print(\"\\n6. Dropping irrelevant columns...\")\n",
    "# These are columns that I deemed unlikely to help predict salary from exploratory analysis and domain knowledge\n",
    "irrelevant_cols = [\n",
    "    'ResponseId', # Unique identifier for each response\n",
    "    'LearnCodeAI', # Did you spend time in the last year learning AI programming or AI-enabled tooling on your own or at work?\n",
    "    # ^ AI not involved in salary prediction, I know some dumb programmers that learned AI\n",
    "    'AILearnedHow', # How did you learn to code for AI in the past year? Select all that apply.\n",
    "    # ^ Method in which AI was learned also not relevant\n",
    "    'TechOppose_15_TEXT', # Text entry for tech oppose question\n",
    "    'JobSatPoints_15_TEXT', # Text entry for job satisfaction question\n",
    "    'Currency', # related to salary - target variable is already in USD\n",
    "    'CompTotal', # related to salary - target variable is already in USD\n",
    "    'LanguagesHaveEntry', # Lot of empty values, not relevant\n",
    "    'LanguagesWantEntry', # Lot of empty values, not relevant\n",
    "    'DatabaseAdmired', # May include useful info, will test with model later\n",
    "    'WebframeAdmired', # May include useful info, will test with model later\n",
    "    'DevEnvsHaveWorkedWith', # May include useful info, will test with model later\n",
    "    'DevEnvsWantToWorkWith', # May include useful info, will test with model later\n",
    "    'DevEnvsAdmired', # May include useful info, will test with model later\n",
    "    'SOTagsHaveWorkedWith', # May include useful info, will test with model later\n",
    "    'SOTagsWantToWorkWith', # May include useful info, will test with model later\n",
    "    'SOTagsAdmired', # May include useful info, will test with model later\n",
    "    'OfficeStackAsyncHaveWorkedWith', # To many different responses, responses are not related to each other too random\n",
    "    'OfficeStackAsyncWantToWorkWith', # To many different responses, responses are not related to each other too random\n",
    "    'OfficeStackAsyncAdmired', # To many different responses, responses are not related to each other too random\n",
    "    'CommPlatformAdmired', # To many different responses, responses are not related to each other too random\n",
    "    'AIModelsChoice', # Not relevant to salary prediction\n",
    "    'AIModelsHaveWorkedWith', # Not relevant to salary prediction\n",
    "    'AIModelsWantToWorkWith', # Not relevant to salary prediction\n",
    "    'AIModelsAdmired', # Not relevant to salary prediction\n",
    "    'AISelect', # Not relevant to salary prediction\n",
    "    'AISent', # Not relevant to salary prediction\n",
    "    'AIAcc', # Not relevant to salary prediction\n",
    "    'AIComplex', # Not relevant to salary prediction\n",
    "    'AIToolCurrently partially AI', # Not relevant to salary prediction\n",
    "    'AIToolDon\\'t plan to use AI for this task', # Not relevant to salary prediction\n",
    "    'AIToolPlan to partially use AI', # Not relevant to salary prediction\n",
    "    'AIToolPlan to mostly use AI', # Not relevant to salary prediction\n",
    "    'AIToolCurrently mostly AI', # Not relevant to salary prediction\n",
    "    'AIFrustration', # Not relevant to salary prediction\n",
    "    'AIExplain', # Not relevant to salary prediction\n",
    "    'AIAgents', # Not relevant to salary prediction\n",
    "    'AIAgentChange', # Not relevant to salary prediction\n",
    "    'AIAgent_Uses', # Not relevant to salary prediction\n",
    "    'AgentUsesGeneral', # Not relevant to salary prediction\n",
    "    'AIAgentImpactSomewhat agree', # Not relevant to salary prediction\n",
    "    'AIAgentImpactNeutral', # Not relevant to salary prediction\n",
    "    'AIAgentImpactSomewhat disagree', # Not relevant to salary prediction\n",
    "    'AIAgentChallengesNeutral', # Not relevant to salary prediction\n",
    "    'AIAgentChallengesSomewhat disagree', # Not relevant to salary prediction\n",
    "    'AIAgentChallengesStrongly agree', # Not relevant to salary prediction\n",
    "    'AIAgentChallengesStrongly disagree', # Not relevant to salary prediction\n",
    "    'AIAgentExternal', # Not relevant to salary prediction\n",
    "    'AIHuman', # Not relevant to salary prediction\n",
    "    'AIOpen', # Not relevant to salary prediction\n",
    "    # Add more irrelevant columns\n",
    "]\n",
    "\n",
    "# Filter to only keep columns that actually exist\n",
    "irrelevant_cols = [col for col in irrelevant_cols if col in df_cleaned.columns]\n",
    "df_cleaned = df_cleaned.drop(columns=irrelevant_cols)\n",
    "print(f\"Dropped {len(irrelevant_cols)} irrelevant columns\")\n",
    "print(f\"Dataset shape after dropping irrelevant columns: {df_cleaned.shape}\")"
   ],
   "id": "e1cc5a496a6d0dec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Dropping irrelevant columns...\n",
      "Dropped 17 irrelevant columns\n",
      "Dataset shape after dropping irrelevant columns: (49123, 82)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 7. Handle missing values in remaining columns\n",
    "print(\"\\n7. Handling missing values...\")\n",
    "numerical_cols = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute numerical columns with median\n",
    "for col in numerical_cols:\n",
    "    if df_cleaned[col].isna().sum() > 0:\n",
    "        df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].median())\n",
    "\n",
    "# Impute categorical columns with 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    if df_cleaned[col].isna().sum() > 0:\n",
    "        df_cleaned[col] = df_cleaned[col].fillna('Unknown')\n",
    "        \n"
   ],
   "id": "2141706f37753999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# LanguageHaveWorkedWith, LanguageWantToWorkWith, LanguageAdmired are strings with multiple values separated by semicolons\n",
    "# Need to convert these columns to be useful for the model\n",
    "# Do the same with DatabaseHaveWorkedWith, DatabaseWantToWorkWith\n",
    "# Do the same with PlatformHaveWorkedWith, PlatformWantToWorkWith\n",
    "# Do the same with WebframeHaveWorkedWith, WebframeWantToWorkWith\n",
    "# OpSysPersonal use, OpSysProfessional use\n",
    "# CommPlatformHaveWorkedWith\n",
    "# CommPlatformWantToWorkWith\n"
   ],
   "id": "ad50b5aec39cac9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
